#READ
#when running this program you will have to exit out of the Ad that pops up in the window on google chrome,
#or else the program will likely crash


import time
from selenium import webdriver
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import poisson


# Define year codes and URL
historical_url = "https://www.premierleague.com/stats/top/clubs/"
historical_stats_parameters = ["goals", "goals_conceded", "ontarget_scoring_att"]
years = {
    "4": {"year": "2023/24", "code": "?se=578", "weight": 4},
    "3": {"year": "2022/23", "code": "?se=489", "weight": 3},
    "2": {"year": "2021/22", "code": "?se=418", "weight": 2},
    "1": {"year": "2020/21", "code": "?se=363", "weight": 1}
}

current_url = "https://www.premierleague.com/tables"
result_mapping = {
                'W': 1,  # Win
                'D': 0.5,  # Draw
                'L': 0  # Loss
            }

# Initialize Selenium driver
driver = webdriver.Chrome()


def page_table_data(year, param, data_list):
    # Parse the page for the table
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    table = soup.find('table')

    # Extract data from the table
    for row in table.find_all('tr')[1:]:  # Skip header
        cells = row.find_all('td')
        if len(cells) >= 3:
            team = cells[1].text.strip()
            value = cells[2].text.strip().replace(",", "")
            if value.isdigit():
                value = int(value)
                data_list.append({"Year": year, "Team": team, param: value})


def get_strengths():
    # Data storage
    goals_data = []
    conceded_data = []
    shots_data = []

    try:
        for vals in years.values():
            year = vals.get("year")
            code = vals.get("code")

            # Loop for both 'goals' and 'goals_conceded'
            for param, data_list in zip(historical_stats_parameters, [goals_data, conceded_data, shots_data]):
                url = historical_url + param + code
                print(f"Fetching {param} data for year {year} from {url}")

                # Start with scraping the first page
                driver.get(url)
                time.sleep(5)  # Wait for JS to load

                page_table_data(year, param, data_list)

                # Check if the "next" button exists and click it
                next_button = driver.find_element(By.XPATH, "/html/body/main/div[2]/div[1]/div[2]/div[2]")
                # Click the "next" button to go to the next page
                print("Clicked next button for more pages.")
                next_button.click()
                time.sleep(5)  # Wait for the next page to load

                page_table_data(year, param, data_list)

    finally:
        driver.quit()

    # Convert both data lists to DataFrames
    goals_df = pd.DataFrame(goals_data)
    conceded_df = pd.DataFrame(conceded_data)
    shots_df = pd.DataFrame(shots_data)

    # Merge both dataframes on 'Year' and 'Team'
    part_df = pd.merge(goals_df, conceded_df, on=["Year", "Team"], how="outer")
    merged_df = pd.merge(part_df, shots_df, on=["Year", "Team"], how="outer")

    # Assign weights based on the 'Year' after merging
    merged_df['Weight'] = merged_df['Year'].map({vals["year"]: vals["weight"] for vals in years.values()})
    merged_df = merged_df.fillna(0)

    merged_df['WeightedGoals'] = merged_df['Weight'] * merged_df['goals']
    merged_df['WeightedMatches'] = merged_df['Weight'] * 38  # Assuming 38 matches per year
    merged_df['WeightedGoalsConceded'] = merged_df['Weight'] * merged_df['goals_conceded']

    # Avoid division by zero in GoalConversionRate calculation
    merged_df['GoalConversionRate'] = merged_df.apply(
        lambda row: row['goals'] / row['ontarget_scoring_att'] if row['ontarget_scoring_att'] > 0 else 0, axis=1
    )

    # Group by team and aggregate relevant statistics
    team_summary = merged_df.groupby('Team').agg({
        'WeightedGoals': 'sum',
        'WeightedMatches': 'sum',
        'WeightedGoalsConceded': 'sum',
        'GoalConversionRate': 'mean'  # Use 'mean' for the average conversion rate
    }).reset_index()

    # Calculate total Offensive Strength and Defensive Strength for each team
    team_summary['OffensiveStrength'] = team_summary['WeightedGoals'] / team_summary['WeightedMatches']
    team_summary['DefensiveStrength'] = 5 - team_summary['WeightedGoalsConceded'] / team_summary['WeightedMatches']

    # Return relevant statistics
    return team_summary[['Team', 'OffensiveStrength', 'DefensiveStrength', 'GoalConversionRate']]


def get_form():
    new_driver = webdriver.Chrome()
    time.sleep(10)
    new_driver.get(current_url)
    time.sleep(5)  # Allow JavaScript to load

    # Get page source and parse with BeautifulSoup
    soup = BeautifulSoup(new_driver.page_source, 'html.parser')

    # Find the relevant data (example: team stats in the table)
    table = soup.find('table')  # Adjust based on the page structure
    rows = table.find_all('tr')[1:]  # Skipping the header row

    # Define the categories
    form_data = []

    # Loop through each row and extract data
    for row in rows:
        cells = row.find_all('td')
        if len(cells) > 1:
            soup = BeautifulSoup(str(row), 'html.parser')

            # Find the match results (in the <ul> under class 'league-table__form form hideMed')
            result_tags = soup.find('td', class_='league-table__form form hideMed').find_all('abbr')

            # Extract match results (W, D, L)
            results = [tag.get_text() for tag in result_tags]

            # Convert results to numeric values
            numeric_results = [result_mapping[result] for result in results]

            # Assign weights (5 for the most recent, 1 for the 5th most recent)
            weights = [5 - i for i in range(len(results))]

            # Get the club name (can be extracted from the 'league-table__team-name' span)
            club_name = soup.find('span', class_='league-table__team-name league-table__team-name--long long').get_text()

            # Create a list of dictionaries for each result and weight
            data = []
            for i in range(len(results)):
                data.append({
                    'Club Name': club_name,
                    'Result': numeric_results[i],
                    'Weight': weights[i]
                })

            # Create a DataFrame from the data for this club
            df = pd.DataFrame(data)

            # Now, calculate the form for this club
            weighted_sum = (df['Result'] * df['Weight']).sum()  # Sum of weight * result
            weight_sum = df['Weight'].sum()  # Sum of weights
            form = weighted_sum / weight_sum  # Calculate form

            # Add the club and form to the form_data list
            form_data.append({'Team': club_name, 'Form': form})

    return pd.DataFrame(form_data)





team_summary = get_strengths()
form_data = get_form()
merged_data = pd.merge(team_summary, form_data, on='Team', how='outer')
merged_data_new = merged_data.dropna(subset=['Form']).reset_index(drop=True)
print(merged_data_new)


current_season_teams = form_data['Team'].unique()
# Teams and data merged from get_strengths and get_form
current_season_data = merged_data[merged_data['Team'].isin(current_season_teams)].reset_index(drop=True)

# Update the teams list
teams = current_season_data['Team'].values
offensive_strength = current_season_data['OffensiveStrength'].values
defensive_strength = current_season_data['DefensiveStrength'].values
recent_form = current_season_data['Form'].values
goal_conversion = current_season_data['GoalConversionRate'].values

# Monte Carlo Simulation Parameters
NUM_SIMULATIONS = 10000
NUM_TEAMS = len(teams)
total_matches = [(i, j) for i in range(NUM_TEAMS) for j in range(NUM_TEAMS) if i != j]
final_points = np.zeros((NUM_SIMULATIONS, NUM_TEAMS))

for sim in range(NUM_SIMULATIONS):
    points = np.zeros(NUM_TEAMS)

    for home, away in total_matches:
        # Adjust strengths using recent form
        O_home = offensive_strength[home] * (1 + 0.05 * recent_form[home]) #chnaged
        D_away = defensive_strength[away] * (1 - 0.05 * recent_form[away])
        O_away = offensive_strength[away] * (1 + 0.05 * recent_form[away])
        D_home = defensive_strength[home] * (1 - 0.05 * recent_form[home])

        # Expected goals (λ values)
        λ_home = max(O_home * D_away * goal_conversion[home], 0.1)  #chnaged
        λ_away = max(O_away * D_home * goal_conversion[away], 0.1)

        # Ensure λ_home and λ_away are not 0 or NaN
        if np.isnan(λ_home) or λ_home <= 0:
            λ_home = 0.01  # Assign a small positive value
        if np.isnan(λ_away) or λ_away <= 0:
            λ_away = 0.01  # Assign a small positive value

        # Simulate goals using Poisson distribution
        goals_home = np.random.poisson(λ_home)
        goals_away = np.random.poisson(λ_away)

        # Assign points
        if goals_home > goals_away:
            points[home] += 3
        elif goals_home < goals_away:
            points[away] += 3
        else:
            points[home] += 1
            points[away] += 1

    final_points[sim] = points

# Aggregate results
average_points = final_points.mean(axis=0)
win_probability = (final_points == final_points.max(axis=1)[:, None]).mean(axis=0)

# Create summary DataFrame
summary_table = pd.DataFrame({
    "Team": teams,
    "Avg Points": average_points,
    "Win Probability": win_probability
}).sort_values(by="Avg Points", ascending=False).reset_index(drop=True)

print(summary_table)

